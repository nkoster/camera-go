<!DOCTYPE HTML>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
<title>Camera</title>
<style>
#container {
  position: relative;
  width: 502px;
  height: 376px;
}
#video {
  position: absolute;
  top: 1px;
  right: 1px;
  width: 125px;
  height: 91px;
}

</style>
</head>
<body>
Your camera ID is <b><span style="padding-right: 20px;" id="localcamid"></span></b> &nbsp; 
Remote camera ID is <b><input type="text" id="remotecamid" /></b><br>
Your microphone ID is <b><span style="padding-right: 20px;" id="localmicid"></span></b> &nbsp; 
Remote microphone ID is <b><input type="text" id="remotemicid" /></b><br>
<button id="start-button" style="margin-left: 40px;">Start</button>
<button id="stop-button">Stop</button><div id="div"></div>
<hr />
<div id="container">
  <video id="video" autoplay></video><audio id="audio"></audio>
  <img id="receive" alt=""/>
</div>
<script>
(() => {
  const
    localCamID = document.getElementById('localcamid'),
    localMicID = document.getElementById('localmicid'),
    remoteCamID = document.getElementById('remotecamid'),
    remoteMicID = document.getElementById('remotemicid'),
    startButton = document.getElementById('start-button'),
    stopButton = document.getElementById('stop-button'),
    display = { width: 502, height: 376, quality: 0.3, fps: 16 },
    interval = 1000 / display.fps,
    proto = location.protocol === 'http:' ? 'ws' : 'wss',
    socketCam = new WebSocket(proto + '://' + location.host + '/cam'),
    socketMic = new WebSocket(proto + '://' + location.host + '/mic'),
    image = document.getElementById('receive'),
    video = document.getElementById('video'),
    audio = document.getElementById('audio'),
    canvas = document.createElement('canvas')

  let
    firstTime = true,
    playing = false

  socketMic.binaryType = 'arraybuffer'

  image.width = display.width
  image.height = display.height

  video.width = display.width
  video.height = display.height

  canvas.width = display.width
  canvas.height = display.height

  socketCam.onmessage = msg => {
    if (typeof msg.data === 'string') {
      localCamID.innerHTML = msg.data
      setTimeout(() => socketCam.send(msg.data), 100)
    } else {
      const blob = new Blob([msg.data], {type: 'image/jpeg'})
      image.src = URL.createObjectURL(blob)
    }
  }

  socketMic.onmessage = msg => {
    if (typeof msg.data === 'string') {
      console.log(msg)
      localMicID.innerHTML = msg.data
      setTimeout(() => socketMic.send(msg.data), 100)
    } else {
      if (playing) {
        audioBuffer = audioCtx.createBuffer(1, 2048, 44100)
        audioBuffer.getChannelData(0).set(new Float32Array(msg.data))
        source = audioCtx.createBufferSource()
        source.buffer = audioBuffer
        source.connect(audioCtx.destination)
        source.start(0)
      }
    }
  }

  startButton.onclick = () => {
    if (!playing && remoteCamID.value.length > 2) {
      navigator.mediaDevices.getUserMedia({ video: true })
      .then(streamCam => {
        if (firstTime) {
          firstTime = false
          socketCam.send(remoteCamID.value)
          remoteCamID.outerHTML = '<span>' + remoteCamID.value + '<span>'
          remoteMicID.outerHTML = '<span>' + remoteMicID.value + '<span>'
        }
        video.setAttribute('autoplay', '')
        video.setAttribute('muted', '')
        video.setAttribute('playsinline', '')
        video.srcObject = streamCam
        playing = true
        audioCtx = new AudioContext()
        track = audioCtx.createMediaElementSource(audio)
        track.connect(audioCtx.destination)
      })
      .catch(err => {
        console.log(err)
      })

      navigator.mediaDevices.getUserMedia({ audio: true })
      .then(streamMic => {
        const context = new AudioContext()
        const source = context.createMediaStreamSource(streamMic)
        const processor = context.createScriptProcessor(2048, 1, 1)
        source.connect(processor)
        processor.connect(context.destination)
        processor.onaudioprocess = evt => {
          playing && socketMic.send(new Float32Array(evt.inputBuffer.getChannelData(0)))
        }
      })
      .catch(err => {
        console.log(err)
      })
    }
  }

  stopButton.onclick = () => {
    video.srcObject &&
    video.srcObject.getTracks().forEach(track => {
      track.stop()
    })
   audio.srcObject &&
    audio.srcObject.getTracks().forEach(track => {
      track.stop()
    })
    playing = false
  }

  const streamer = setInterval(() => {
    if (playing) {
      canvas.getContext('2d').drawImage(video, 0, 0, display.width, display.height)
      canvas.toBlob(blob => { socketCam.send(blob) }, 'image/jpeg', display.quality)
    }
  }, interval)

})()
</script>
</body>
</html>
